2025-03-18 12:33:56 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:33:56 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:33:56 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:33:56 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:33:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:33:56 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:33:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:33:56 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:33:56 [scrapy.extensions.telnet] INFO: Telnet Password: 3c42bd931b5f812a
2025-03-18 12:33:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:33:56 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:33:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:33:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:33:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:33:57 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:33:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:33:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:33:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:33:57 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:33:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46394,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.661172,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 33, 57, 689710, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 33, 57, 28538, tzinfo=datetime.timezone.utc)}
2025-03-18 12:33:57 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:34:30 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:34:30 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:34:30 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:34:30 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:34:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:34:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:34:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:34:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:34:30 [scrapy.extensions.telnet] INFO: Telnet Password: 6da9888ee234addf
2025-03-18 12:34:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:34:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:34:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:34:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:34:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:34:30 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:34:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:34:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:34:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:31 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:34:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46384,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.685825,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 34, 31, 397248, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 34, 30, 711423, tzinfo=datetime.timezone.utc)}
2025-03-18 12:34:31 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:34:57 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:34:57 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:34:57 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:34:57 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:34:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:34:57 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:34:57 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:34:57 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:34:57 [scrapy.extensions.telnet] INFO: Telnet Password: 3a0c581715e20a09
2025-03-18 12:34:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:34:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:34:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:34:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:34:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:34:57 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:34:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:34:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:34:58 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:34:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46394,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.616538,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 34, 58, 510718, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 34, 57, 894180, tzinfo=datetime.timezone.utc)}
2025-03-18 12:34:58 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:38:10 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:38:10 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:38:10 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:38:10 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:38:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:38:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:38:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:38:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:38:10 [scrapy.extensions.telnet] INFO: Telnet Password: ea4e361b8cfb8b1b
2025-03-18 12:38:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:38:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:38:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:38:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:38:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:38:10 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:38:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:38:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:38:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:38:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:38:11 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:38:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.653511,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 38, 11, 326796, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 38, 10, 673285, tzinfo=datetime.timezone.utc)}
2025-03-18 12:38:11 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:40:39 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:40:40 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:40:40 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:40:40 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:40:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:40:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:40:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:40:40 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:40:40 [scrapy.extensions.telnet] INFO: Telnet Password: f1a27073fa7a08a0
2025-03-18 12:40:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:40:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:40:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:40:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:40:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:40:40 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:40:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:40:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:40:40 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:40:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.675678,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 40, 40, 986321, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 40, 40, 310643, tzinfo=datetime.timezone.utc)}
2025-03-18 12:40:40 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:41:16 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:41:16 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:41:16 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:41:16 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:41:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:41:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:41:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:41:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:41:16 [scrapy.extensions.telnet] INFO: Telnet Password: 85231ac73c3f0a33
2025-03-18 12:41:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:41:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:41:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:41:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:41:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:41:16 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:41:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:41:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:41:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:41:17 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_7.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_2.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_24.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_25.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_21.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_25.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_22.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_25.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_20.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_25.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_23.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_25.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_8.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_5.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_11.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_6.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_12.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_7.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_9.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_5.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_10.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_5.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_19.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_24.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_17.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_22.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_15.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_20.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_16.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_21.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_18.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_22.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_13.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_8.html)
2025-03-18 12:41:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_14.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian_11.html)
2025-03-18 12:41:17 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:41:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7728,
 'downloader/request_count': 25,
 'downloader/request_method_count/GET': 25,
 'downloader/response_bytes': 159536,
 'downloader/response_count': 25,
 'downloader/response_status_count/200': 25,
 'dupefilter/filtered': 210,
 'elapsed_time_seconds': 1.14711,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 41, 17, 925662, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 843777,
 'httpcompression/response_count': 25,
 'items_per_minute': None,
 'log_count/DEBUG': 31,
 'log_count/INFO': 10,
 'request_depth_max': 4,
 'response_received_count': 25,
 'responses_per_minute': None,
 'scheduler/dequeued': 25,
 'scheduler/dequeued/memory': 25,
 'scheduler/enqueued': 25,
 'scheduler/enqueued/memory': 25,
 'start_time': datetime.datetime(2025, 3, 18, 4, 41, 16, 778552, tzinfo=datetime.timezone.utc)}
2025-03-18 12:41:17 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:47:26 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:47:27 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:47:27 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:47:27 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:47:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:47:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:47:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:47:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:47:27 [scrapy.extensions.telnet] INFO: Telnet Password: fe835307dd1437ae
2025-03-18 12:47:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:47:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:47:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:47:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:47:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:47:27 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:47:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:47:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:47:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list")]/div/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 12:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:47:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list")]/div/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 12:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list")]/div/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 12:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list")]/div/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 12:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list")]/div/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 12:47:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list")]/div/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 12:47:28 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:47:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46389,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.756193,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 47, 28, 73950, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/ERROR': 6,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'spider_exceptions/AttributeError': 6,
 'start_time': datetime.datetime(2025, 3, 18, 4, 47, 27, 317757, tzinfo=datetime.timezone.utc)}
2025-03-18 12:47:28 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:49:13 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:49:14 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:49:14 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:49:14 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:49:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:49:14 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:49:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:49:14 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:49:14 [scrapy.extensions.telnet] INFO: Telnet Password: 3b3649b63ff0468d
2025-03-18 12:49:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:49:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:49:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:49:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:49:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:49:14 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:49:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:49:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:49:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:49:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:49:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:49:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:49:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:49:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:49:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:49:15 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:49:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46388,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.703339,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 49, 15, 233686, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 49, 14, 530347, tzinfo=datetime.timezone.utc)}
2025-03-18 12:49:15 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:52:20 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:52:20 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:52:20 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:52:20 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:52:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:52:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:52:20 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:52:20 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:52:20 [scrapy.extensions.telnet] INFO: Telnet Password: e99fc4e0ffae1052
2025-03-18 12:52:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:52:20 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:52:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:52:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:52:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:52:20 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:52:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:52:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:52:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:52:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:52:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:52:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:52:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:52:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:52:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:52:21 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:52:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46390,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.723611,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 52, 21, 407778, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 52, 20, 684167, tzinfo=datetime.timezone.utc)}
2025-03-18 12:52:21 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:53:44 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:53:44 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:53:44 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:53:44 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:53:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:53:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:53:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:53:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:53:44 [scrapy.extensions.telnet] INFO: Telnet Password: cc9f1c79a548a7f4
2025-03-18 12:53:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:53:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:53:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:53:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:53:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:53:44 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:53:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:53:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:53:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:53:45 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:53:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.566109,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 53, 45, 432718, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 53, 44, 866609, tzinfo=datetime.timezone.utc)}
2025-03-18 12:53:45 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:57:51 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:57:51 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:57:51 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:57:51 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:57:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:57:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:57:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:57:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:57:51 [scrapy.extensions.telnet] INFO: Telnet Password: b7f04a02b6f2e842
2025-03-18 12:57:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:57:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:57:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:57:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:57:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:57:52 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:57:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:57:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:57:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:57:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:57:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:57:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:57:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:57:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:57:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:57:52 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:57:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46392,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.548229,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 57, 52, 682624, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 57, 52, 134395, tzinfo=datetime.timezone.utc)}
2025-03-18 12:57:52 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 12:58:27 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 12:58:27 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 12:58:27 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 12:58:27 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 12:58:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:58:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:58:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 12:58:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 12:58:27 [scrapy.extensions.telnet] INFO: Telnet Password: 968ceee21d04dd47
2025-03-18 12:58:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 12:58:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 12:58:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 12:58:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 12:58:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 12:58:27 [scrapy.core.engine] INFO: Spider opened
2025-03-18 12:58:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 12:58:28 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 12:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 12:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:58:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 12:58:28 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 12:58:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46394,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.539027,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 4, 58, 28, 542643, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 4, 58, 28, 3616, tzinfo=datetime.timezone.utc)}
2025-03-18 12:58:28 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:00:00 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:00:00 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:00:00 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:00:00 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:00:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:00:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:00:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:00:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:00:00 [scrapy.extensions.telnet] INFO: Telnet Password: 8bea151d3164a3e8
2025-03-18 13:00:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:00:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:00:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:00:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:00:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:00:00 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:00:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:00:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:00:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:00:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46389,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.677872,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 0, 1, 599168, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 0, 0, 921296, tzinfo=datetime.timezone.utc)}
2025-03-18 13:00:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:06:50 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:06:50 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:06:50 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:06:50 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:06:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:06:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:06:50 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:06:50 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:06:50 [scrapy.extensions.telnet] INFO: Telnet Password: 004b23337f7aa29f
2025-03-18 13:06:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:06:50 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:06:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:06:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:06:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:06:51 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:06:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:06:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:06:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:06:51 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:06:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46392,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.636596,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 6, 51, 656884, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 6, 51, 20288, tzinfo=datetime.timezone.utc)}
2025-03-18 13:06:51 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:07:27 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:07:27 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:07:27 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:07:27 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:07:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:07:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:07:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:07:27 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:07:27 [scrapy.extensions.telnet] INFO: Telnet Password: a8e2ecb5eec7a9c7
2025-03-18 13:07:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:07:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:07:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:07:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:07:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:07:27 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:07:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:07:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:07:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:07:28 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:07:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46393,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.661124,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 7, 28, 549028, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 7, 27, 887904, tzinfo=datetime.timezone.utc)}
2025-03-18 13:07:28 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:16:53 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:16:53 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:16:53 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:16:53 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:16:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:16:53 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:16:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:16:53 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:16:53 [scrapy.extensions.telnet] INFO: Telnet Password: b946073d8178ce89
2025-03-18 13:16:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:16:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:16:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:16:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:16:54 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:16:54 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:16:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:16:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:16:54 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:16:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46393,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.572961,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 16, 54, 695806, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 16, 54, 122845, tzinfo=datetime.timezone.utc)}
2025-03-18 13:16:54 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:17:11 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:17:11 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:17:11 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:17:11 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:17:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:17:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:17:11 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:17:11 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:17:11 [scrapy.extensions.telnet] INFO: Telnet Password: cd6ca6539ef5d116
2025-03-18 13:17:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:17:11 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:17:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:17:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:17:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:17:12 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:17:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:17:12 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:17:12 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:17:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46390,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.694997,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 17, 12, 782375, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 17, 12, 87378, tzinfo=datetime.timezone.utc)}
2025-03-18 13:17:12 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:21:00 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:21:00 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:21:00 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:21:00 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:21:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:21:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:21:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:21:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:21:00 [scrapy.extensions.telnet] INFO: Telnet Password: 561a448babce1a8b
2025-03-18 13:21:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:21:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:21:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:21:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:21:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:21:01 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:21:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:21:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:21:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46394,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.560348,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 21, 1, 716135, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 21, 1, 155787, tzinfo=datetime.timezone.utc)}
2025-03-18 13:21:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:21:16 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:21:16 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:21:16 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:21:16 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:21:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:21:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:21:16 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:21:16 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:21:16 [scrapy.extensions.telnet] INFO: Telnet Password: aed43da982ad6574
2025-03-18 13:21:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:21:16 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:21:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:21:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:21:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:21:17 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:21:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:21:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:17 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:21:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46390,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.724605,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 21, 17, 973446, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 21, 17, 248841, tzinfo=datetime.timezone.utc)}
2025-03-18 13:21:17 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:21:35 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:21:35 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:21:35 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:21:35 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:21:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:21:35 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:21:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:21:35 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:21:35 [scrapy.extensions.telnet] INFO: Telnet Password: e0d0e071aa9aabea
2025-03-18 13:21:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:21:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:21:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:21:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:21:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:21:35 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:21:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:21:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:21:36 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:21:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46390,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.725159,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 21, 36, 706880, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 21, 35, 981721, tzinfo=datetime.timezone.utc)}
2025-03-18 13:21:36 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:22:02 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:22:02 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:22:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:22:02 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:22:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:22:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:22:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:22:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:22:02 [scrapy.extensions.telnet] INFO: Telnet Password: 01f1648768af3995
2025-03-18 13:22:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:22:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:22:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:22:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:22:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:22:02 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:22:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:22:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:22:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:22:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:03 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:22:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.680074,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 22, 3, 489734, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 22, 2, 809660, tzinfo=datetime.timezone.utc)}
2025-03-18 13:22:03 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:22:30 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:22:30 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:22:30 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:22:30 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:22:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:22:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:22:30 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:22:30 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:22:30 [scrapy.extensions.telnet] INFO: Telnet Password: b65b3293dfee905e
2025-03-18 13:22:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:22:30 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:22:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:22:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:22:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:22:30 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:22:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:22:30 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:22:31 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:22:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46388,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.853988,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 22, 31, 844102, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 22, 30, 990114, tzinfo=datetime.timezone.utc)}
2025-03-18 13:22:31 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:23:00 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:23:00 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:23:00 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:23:00 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:23:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:23:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:23:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:23:00 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:23:00 [scrapy.extensions.telnet] INFO: Telnet Password: 72c60d07d8d7deb0
2025-03-18 13:23:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:23:00 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:23:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:23:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:23:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:23:01 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:23:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:23:01 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').extract().getall()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'getall'
2025-03-18 13:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').extract().getall()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'getall'
2025-03-18 13:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').extract().getall()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'getall'
2025-03-18 13:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').extract().getall()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'getall'
2025-03-18 13:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').extract().getall()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'getall'
2025-03-18 13:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').extract().getall()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'getall'
2025-03-18 13:23:01 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:23:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.623036,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 23, 1, 724714, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/ERROR': 6,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'spider_exceptions/AttributeError': 6,
 'start_time': datetime.datetime(2025, 3, 18, 5, 23, 1, 101678, tzinfo=datetime.timezone.utc)}
2025-03-18 13:23:01 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:23:18 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:23:18 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:23:18 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:23:18 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:23:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:23:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:23:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:23:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:23:18 [scrapy.extensions.telnet] INFO: Telnet Password: 1ad16af5b91f62b5
2025-03-18 13:23:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:23:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:23:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:23:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:23:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:23:19 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:23:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:23:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 13:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 13:23:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 13:23:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 13:23:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 13:23:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
Traceback (most recent call last):
  File "D:\pt2\Lib\site-packages\scrapy\utils\defer.py", line 346, in aiter_errback
    yield await it.__anext__()
          ^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 394, in __anext__
    return await self.data.__anext__()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\pt2\Lib\site-packages\scrapy\utils\python.py", line 375, in _async_chain
    async for o in as_async_generator(it):
  File "D:\pt2\Lib\site-packages\scrapy\utils\asyncgen.py", line 21, in as_async_generator
    async for r in it:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\referer.py", line 384, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 62, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spidermiddlewares\depth.py", line 60, in process_spider_output_async
    async for r in result:
  File "D:\pt2\Lib\site-packages\scrapy\core\spidermw.py", line 121, in process_async
    async for r in iterable:
  File "D:\pt2\Lib\site-packages\scrapy\spiders\crawl.py", line 161, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "X:\桌面\pythyon_\爬虫demo\爬虫method\scrapy_zhanzhangsucai\scrapy_zhanzhangsucai\spiders\zhanzhang_try.py", line 16, in parse_item
    src_list = response.xpath('//div/div[contains(@class, "tupian-list com-img-txt-list")]/div[contains(@class, "item")]/img/@data-original').getall().extract()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'extract'
2025-03-18 13:23:19 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:23:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46394,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.614178,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 23, 19, 764592, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/ERROR': 6,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'spider_exceptions/AttributeError': 6,
 'start_time': datetime.datetime(2025, 3, 18, 5, 23, 19, 150414, tzinfo=datetime.timezone.utc)}
2025-03-18 13:23:19 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:23:36 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:23:36 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:23:36 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:23:36 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:23:36 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:23:36 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:23:36 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:23:36 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:23:36 [scrapy.extensions.telnet] INFO: Telnet Password: a2ea36c965765e7b
2025-03-18 13:23:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:23:36 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:23:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:23:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:23:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:23:36 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:23:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:23:36 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:23:37 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:23:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46390,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.778107,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 23, 37, 483584, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 23, 36, 705477, tzinfo=datetime.timezone.utc)}
2025-03-18 13:23:37 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:24:02 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:24:02 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:24:02 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:24:02 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:24:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:24:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:24:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:24:02 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:24:02 [scrapy.extensions.telnet] INFO: Telnet Password: 4a04b9cda5cc8bb3
2025-03-18 13:24:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:24:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:24:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:24:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:24:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:24:02 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:24:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:24:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:03 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:24:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.615398,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 24, 3, 16653, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 24, 2, 401255, tzinfo=datetime.timezone.utc)}
2025-03-18 13:24:03 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:24:35 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:24:35 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:24:35 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:24:35 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:24:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:24:35 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:24:35 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:24:35 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:24:35 [scrapy.extensions.telnet] INFO: Telnet Password: efc86e6c756a3ba8
2025-03-18 13:24:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:24:35 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:24:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:24:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:24:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:24:35 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:24:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:24:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:24:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:24:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:36 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:24:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46392,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.619202,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 24, 36, 192934, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 24, 35, 573732, tzinfo=datetime.timezone.utc)}
2025-03-18 13:24:36 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:24:55 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:24:55 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:24:55 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:24:55 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:24:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:24:55 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:24:55 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:24:55 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:24:55 [scrapy.extensions.telnet] INFO: Telnet Password: 7c02a85c6f81d94d
2025-03-18 13:24:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:24:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:24:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:24:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:24:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:24:55 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:24:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:24:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:24:56 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:24:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46392,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.546078,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 24, 56, 406580, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 24, 55, 860502, tzinfo=datetime.timezone.utc)}
2025-03-18 13:24:56 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:27:17 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:27:17 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:27:17 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:27:17 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:27:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:27:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:27:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:27:17 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:27:17 [scrapy.extensions.telnet] INFO: Telnet Password: 0084908d437db882
2025-03-18 13:27:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:27:17 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:27:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:27:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:27:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:27:17 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:27:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:27:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:27:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:27:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:27:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:27:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:27:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:27:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:27:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:27:18 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:27:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46392,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.669334,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 27, 18, 245252, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 27, 17, 575918, tzinfo=datetime.timezone.utc)}
2025-03-18 13:27:18 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:33:42 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:33:42 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:33:42 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:33:42 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:33:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:33:42 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:33:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:33:42 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:33:42 [scrapy.extensions.telnet] INFO: Telnet Password: e9d3ef1791b09c13
2025-03-18 13:33:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:33:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:33:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:33:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:33:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:33:42 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:33:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:33:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:33:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:33:43 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:33:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.84228,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 33, 43, 495447, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 33, 42, 653167, tzinfo=datetime.timezone.utc)}
2025-03-18 13:33:43 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:37:03 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:37:03 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:37:03 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:37:03 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:37:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:37:03 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:37:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:37:03 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:37:03 [scrapy.extensions.telnet] INFO: Telnet Password: 59e5e52d1538fbc9
2025-03-18 13:37:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:37:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:37:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:37:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:37:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:37:03 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:37:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:37:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:37:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:37:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:37:04 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:37:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46389,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.793357,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 37, 4, 495760, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 37, 3, 702403, tzinfo=datetime.timezone.utc)}
2025-03-18 13:37:04 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:38:03 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:38:03 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:38:03 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:38:03 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:38:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:38:03 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:38:03 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:38:03 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:38:03 [scrapy.extensions.telnet] INFO: Telnet Password: 6930e81bafd043c3
2025-03-18 13:38:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:38:03 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:38:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:38:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:38:03 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:38:03 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:38:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:38:03 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:38:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:38:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:04 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:38:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46394,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.681577,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 38, 4, 386843, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 38, 3, 705266, tzinfo=datetime.timezone.utc)}
2025-03-18 13:38:04 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:38:51 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:38:51 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:38:51 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:38:51 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:38:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:38:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:38:51 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:38:51 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:38:51 [scrapy.extensions.telnet] INFO: Telnet Password: 3bfe6b65cccfbf4e
2025-03-18 13:38:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:38:51 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:38:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:38:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:38:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:38:51 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:38:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:38:51 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:38:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:38:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:38:52 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:38:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46388,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.704472,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 38, 52, 527509, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 38, 51, 823037, tzinfo=datetime.timezone.utc)}
2025-03-18 13:38:52 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:40:44 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:40:44 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:40:44 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:40:44 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:40:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:40:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:40:44 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:40:44 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:40:44 [scrapy.extensions.telnet] INFO: Telnet Password: e63477d9348f1f8f
2025-03-18 13:40:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:40:44 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:40:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:40:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:40:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:40:44 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:40:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:40:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:40:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:40:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:40:45 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:40:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46390,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.706985,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 40, 45, 332381, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 40, 44, 625396, tzinfo=datetime.timezone.utc)}
2025-03-18 13:40:45 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:48:10 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:48:10 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:48:10 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:48:10 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:48:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:48:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:48:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:48:10 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:48:10 [scrapy.extensions.telnet] INFO: Telnet Password: 6cb3d631930b2aab
2025-03-18 13:48:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:48:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:48:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:48:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:48:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:48:10 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:48:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:48:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:48:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:48:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:48:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:48:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:48:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:48:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:48:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:48:11 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:48:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46391,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.683052,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 48, 11, 372007, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 48, 10, 688955, tzinfo=datetime.timezone.utc)}
2025-03-18 13:48:11 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:50:28 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:50:28 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:50:28 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:50:28 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:50:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:50:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:50:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:50:28 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:50:28 [scrapy.extensions.telnet] INFO: Telnet Password: 5eb95c6d8ffd2df1
2025-03-18 13:50:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:50:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:50:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:50:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:50:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:50:29 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:50:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:50:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:50:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:50:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_2.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:50:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_25.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:50:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_5.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:50:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_4.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:50:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_6.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:50:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian_3.html> (referer: https://sc.chinaz.com/tupian/xiaomaotupian.html)
2025-03-18 13:50:29 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:50:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2104,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 46393,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 7,
 'elapsed_time_seconds': 0.577682,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 50, 29, 737015, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 235169,
 'httpcompression/response_count': 7,
 'items_per_minute': None,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'request_depth_max': 1,
 'response_received_count': 7,
 'responses_per_minute': None,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'start_time': datetime.datetime(2025, 3, 18, 5, 50, 29, 159333, tzinfo=datetime.timezone.utc)}
2025-03-18 13:50:29 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:50:59 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:50:59 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:50:59 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:50:59 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:50:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:50:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:50:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:50:59 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:50:59 [scrapy.extensions.telnet] INFO: Telnet Password: 2056034485830e95
2025-03-18 13:50:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:50:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:51:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:51:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:51:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:51:00 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:51:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:51:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:51:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:51:00 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:51:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 249,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6916,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.352815,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 51, 0, 513033, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 35494,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 3, 18, 5, 51, 0, 160218, tzinfo=datetime.timezone.utc)}
2025-03-18 13:51:00 [scrapy.core.engine] INFO: Spider closed (finished)
2025-03-18 13:51:18 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapy_zhanzhangsucai)
2025-03-18 13:51:18 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-11-10.0.26100-SP0
2025-03-18 13:51:18 [scrapy.addons] INFO: Enabled addons:
[]
2025-03-18 13:51:18 [asyncio] DEBUG: Using selector: SelectSelector
2025-03-18 13:51:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:51:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:51:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-03-18 13:51:18 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-03-18 13:51:18 [scrapy.extensions.telnet] INFO: Telnet Password: ce38f430c5b81e79
2025-03-18 13:51:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2025-03-18 13:51:18 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'scrapy_zhanzhangsucai',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_zhanzhangsucai.log',
 'NEWSPIDER_MODULE': 'scrapy_zhanzhangsucai.spiders',
 'SPIDER_MODULES': ['scrapy_zhanzhangsucai.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-03-18 13:51:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-03-18 13:51:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-03-18 13:51:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2025-03-18 13:51:19 [scrapy.core.engine] INFO: Spider opened
2025-03-18 13:51:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-03-18 13:51:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-03-18 13:51:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://sc.chinaz.com/tupian/xiaomaotupian.html> (referer: None)
2025-03-18 13:51:19 [scrapy.core.engine] INFO: Closing spider (finished)
2025-03-18 13:51:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 249,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6916,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.362011,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 3, 18, 5, 51, 19, 532364, tzinfo=datetime.timezone.utc),
 'httpcompression/response_bytes': 35494,
 'httpcompression/response_count': 1,
 'items_per_minute': None,
 'log_count/DEBUG': 6,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'responses_per_minute': None,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2025, 3, 18, 5, 51, 19, 170353, tzinfo=datetime.timezone.utc)}
2025-03-18 13:51:19 [scrapy.core.engine] INFO: Spider closed (finished)
